{"name":"Bounded-intmap","tagline":"A reimplementation of `Data.IntMap` that uses minimum and maximum bounds on subtrees instread of bit prefixes.","body":"bounded-intmap\r\n==============\r\n\r\n`bounded-intmap` is a reimplementation of `Data.IntMap` that uses minimum and maximum bounds on subtrees instread of bit prefixes. The original idea, by Edward Kmett, is described [here](https://www.fpcomplete.com/user/edwardk/revisiting-matrix-multiplication/part-4). As per my current benchmark results, this implemenation seems to range from 33% faster to 50% slower than stock `Data.IntMap`. Note that only three types of function in the benchmark, `insert`, `intersection`, and `foldlWithKey`, are slower than stock `Data.IntMap`, and even then `insert` is only slower if the key is not already present in the map.\r\n\r\nI deviate from the original implementation in a couple of ways:\r\n\r\n* I removed the redundant encoding of bounds. Previously, you might have a tree like this:\r\n\r\n               0,7\r\n              /    \\\r\n           0,3      4,7 \r\n          /   \\     /  \\\r\n        0,1   2,3  4,5  6,7\r\n\r\n  Now, you have trees like this:\r\n\r\n          0,7\r\n          /  \\\r\n         3    4 \r\n        / \\  / \\\r\n       1   2 5  6\r\n\r\n  Note that this means that this implementation consumes less memory than the current `Data.IntMap`.\r\n\r\n* I factored the datatype into two pieces: `Node` for non-empty trees, and `WordMap` for possibly empty trees.\r\n* I cache some of the computation for locating a key as I traverse the key, making it quicker to decide which way to go.\r\n\r\nDescription of the internals\r\n----------------------------\r\n### The basic integer map: the bitwise trie ###\r\nWe are trying to create an efficient, simple mapping from integers to values. The most common approaches for these are hash tables, which are not persistent (though we can come close with HAMTs), and binary search trees, which work well, but don't use any special properties of the integer. To come up with this mapping, we need to think of integers not as numbers, but instead as strings of bits. Once we change our mindset, we can use the standard _trie_ data structure to build our mapping. As bits are particularly simple, so is the resulting structure:\r\n\r\n```haskell\r\ndata WordMap a = Bin (WordMap a) (WordMap a) | Tip a | Nil\r\n```\r\n\r\nThe `Bin` constructor represents a bitwise branch, and the `Tip` constructor comes after (on my machine) 64 `Bin` construtors in the tree. The associated basic operations are fairly simple:\r\n\r\n```haskell\r\nlookup :: Word -> WordMap a -> Maybe a\r\nlookup k = go 0\r\n  where\r\n    go b (Bin l r) = if testBit b k\r\n                     then go (b + 1) l\r\n                     else go (b + 1) r\r\n    go _ (Tip x) = Just x\r\n    go _ Nil = Nothing\r\n\r\ninsert :: Word -> a -> WordMap a -> WordMap a\r\ninsert k a = go 0\r\n  where\r\n    go 64 _ = Tip a\r\n    go b (Bin l r) = if testBit b k\r\n                     then Bin (go (b + 1) l) r\r\n                     else Bin l (go (b + 1) r)\r\n    go b _ = if testBit b k\r\n             then Bin (go (b + 1) Nil) Nil\r\n             else Bin Nil (go (b + 1) Nil)\r\n```\r\n\r\n`delete` follows similarly, and `union` isn't to hard - I leave it as an exercise to the reader. Unfortunately, this approach is horribly slow and space efficient. To see why, let us look at the tree structure for `singleton 5 \"hello\"`:\r\n\r\n```\r\n\\0\r\n \\0\r\n  \\0\r\n   \\0\r\n    \\0\r\n     \\0\r\n      \\0\r\n       \\0\r\n        \\0\r\n         \\0\r\n          \\0\r\n           \\0\r\n            \\0\r\n           1/\r\n            \\0\r\n           1/\r\n         \"hello\"\r\n```\r\n\r\nNote that, for brevity, I have shortened the word size to 16 bits - the diagram is 4 times larger for our 64 bit system. In this atrocious tree structure, there is one pointer for every bit - a 64 fold explosion in space. Arguably worse is the fact that every single `lookup` or `insert` or `delete` must traverse 64 pointers, resulting in 64 cache misses and a terrible runtime. So, how do we fix this?\r\n\r\n### Path compression: PATRICIA trees and stock `Data.IntMap` ###\r\nThe key observation to reducing the space usage is that we can compress nodes that only have one child together - since they form a linear chain, we can simply concatenate the bits within that chain. For example, again temporarily shortening the word size to 16 bits:\r\n\r\n```\r\nsingleton 5 \"hello\":\r\n\r\n| 0000000000000101\r\n\"hello\"\r\n\r\nfromList [(1, \"1\"), (4, \"4\"), (5, \"5\")]:\r\n\r\n     | 0000000000000___\r\n001/  \\10_\r\n\"1\"  0/ \\1\r\n    \"4\" \"5\"\r\n```\r\n\r\nThis clearly produces a much more space efficient structure, and the basic operations, while more complicated, are still straightforward. In Haskell, the structure is:\r\n\r\n```haskell\r\ndata WordMap a = Bin Prefix Mask (WordMap a) (WordMap a) | Tip Word a | Nil\r\n```\r\n\r\nNote that in the above representation, the `Mask` is used to tell how long the `Prefix` is, and the `Word` in the `Tip` nodes is to avoid the for using `Bin` for singletons. This final representation is known as the big-endian PATRICIA tree, and is what today's `Data.IntMap` uses internally, albeit with some optimizations like strictness and unpacking, which I have omitted for simplicity. However, we can take this structure a few steps farther, which is the goal of this package.\r\n\r\n### Implicit prefixes: a simpler representation ###\r\n\r\nThe central observation for this step comes from Edward Kmett, as mentioned in a previous section. In the PATRICIA tree representation, we explicitly stored the common prefix of all the keys in a subtree. However, this prefix is not needed if we know what the largest and smallest keys stored within a subtree are - the common prefix of all the keys is just the common prefix of the minimum and maximum keys. Using this observation, we get another representation:\r\n\r\n```haskell\r\ndata WordMap a = Bin Word Word (WordMap a) (WordMap a) | Tip Word a | Nil\r\n```\r\n\r\nIn tree form:\r\n```\r\nsingleton 5 hello:\r\n\r\n| 5\r\n\"hello\"\r\n\r\nfromList [(1, \"1\"), (4, \"4\"), (5, \"5\")]:\r\n\r\n    | (1, 5)\r\n  1/  \\ (4, 5)\r\n\"1\"  4/ \\5\r\n    \"4\"  \"5\"\r\n```\r\n\r\nTraversing this tree efficiently is a bit more difficult, but still possible. For details, see the section below titled \"Figuring out which way to go\". This representation, since it gives exact minimums and maximums, can actually be more efficient than the PATRICIA tree, as seaches can terminate earlier. The range of values between the minimum and maximum is generally smaller than the range of values with the correct prefix, and so searches will know earlier if they are going to fail. However, the big gains of this representation come after a few more steps.\r\n\r\n### Removing redundancy ###\r\nYou may have noticed that the above representation store many keys repeatedly - in the {1,4,5} example, 1 was stored twice, 4 was stored twice, and 5 was stored three times. The reason for this is very simple. In the {1,4,5} example, we knew that the minimum was 1 and the maximum was 5. At the first branch, we split the set into two parts - {1} and {4,5}. However, the minimum of the smaller set was exactly the minimum of the original set. Similarly, the maximum of the larger set was exactly the maximum of the original set. Since we always travers the tree downward, this information is not needed. We can restructure the tree to only store 1 new value at each branch, removing the redundancy. Note that we also have to add an extra value at the root node, where this transformation does not work. In summary:\r\n\r\n```haskell\r\ndata WordMap a = Empty | NonEmpty Word (Node a)\r\ndata Node a = Bin Word (Node a) (Node a) | Tip a\r\n```\r\n\r\nIn tree form:\r\n```\r\n    | 1\r\n    | 5\r\n   / \\\r\n\"1\" 4/ \\\r\n   \"4\"  \"5\"\r\n```\r\n\r\nWith this optimization, the operations get more complicated again, but we have achieved something amazing - this new representation is more memory efficient than stock `Data.IntMap`. We will improve this again, as well as the runtime, with our final optimization.\r\n\r\n### Moving the values upward ###\r\nIf you look carefully at the tree structure from the previous section, you will notice that we removed the redundancy perfectly - every key is stored exactly once. However, if the keys are stored in a unique location in the tree, why are the values stored far away? We can move the values upward in the tree to pair them with their keys and so get a simpler structure.\r\n\r\nIn Haskell:\r\n```haskell\r\ndata WordMap a = Empty | NonEmpty Word a (Node a)\r\ndata Node a = Bin Word a (Node a) (Node a) | Tip\r\n```\r\n\r\nIn tree form:\r\n```\r\n    | 1 \"1\"\r\n    | 5 \"5\"\r\n   / \\\r\n     / \\ 4 \"4\"\r\n```\r\n\r\nAt first, this seems to improve neither runtime nor space usage - after all, all we did was move the values around. However, the `Tip` constructor is now empty, meaning that it can be shared among all the leaves of every tree. The `Tip` constructor essentiall disappears from the space usage profile, and we get a gain in memory. The runtime effect is even larger. Because the values are now high in the tree, functions like `lookup` don't have to go all the way to the leaves. This means following fewer pointers, which means fewer cache misses and just a shorter loop. Admittedly, after all this work, our functions have become much larger than the sizes they started with, but we have won speed gains and significant memory gains from the current state of the art.\r\n\r\n### Figuring out which way to go ###\r\nSuppose we are looking up a key `k` in a tree. We know that the minimum key in the tree is `min` and that the maximum key is `max`. Represented in binary:\r\n\r\n             shared prefix   bit to split on\r\n               /----------\\  /\r\n    min:       010010010101 0 ????????\r\n    max:       010010010101 1 ????????\r\n    k:         010010010101 ? ????????\r\n\r\nTo figure out in which subtree we need to recursively search for `k`, we need to know whether the bit to split on is zero or one. Now, if it is zero, then\r\n\r\n    xor min k: 000000000000 0 ????????\r\n    xor k max: 000000000000 1 ????????\r\n\r\nIf it is one:\r\n\r\n    xor min k: 000000000000 1 ????????\r\n    xor k max: 000000000000 0 ????????\r\n\r\nTherefore, the splitting bit is set iff `xor min k > xor k max`. Taking the terminology from the original article, `insideR k min max = xor min k > xor k max`.\r\n\r\nBenchmark Results\r\n-----------------\r\n\r\nThe criterion report is [here](https://gereeter.github.io/bounded-intmap/report.html).\r\n\r\nCurrent Progress\r\n----------------\r\nBelow is a listing of every function in stock `Data.IntMap`, along with the implementation state in `bounded-intmap`. There are three implementation states:\r\n\r\n* Raw means that I have implemented the function directly. These functions should be on par with or faster than their corresponding functions in stock `Data.IntMap`.\r\n* Delegated means that I have implemented the function, but in terms of other functions. This usually means that it will be slower than stock `Data.IntMap`, sometimes asymptotically, and I haven't figured out how to implement it (or implement it nicely) yet. Note that some functions marked as such, like `insertWithKey`, are trivial uses of other functions are should have almost no performance hit.\r\n* Unimplemented means that I have yet to implement the function in any form.\r\n\r\n### Operators\r\n* `(!)`. Delegated, using `findWithDefault`.\r\n* `(\\\\)`. Delegated, using `difference`.\r\n\r\n### Query\r\n* `null`. Raw.\r\n* `size`. Raw.\r\n* `member`. Raw.\r\n* `notMember`. Raw.\r\n* `lookup`. Raw.\r\n* `findWithDefault`. Raw.\r\n* `lookupLT`. Raw.\r\n* `lookupGT`. Raw.\r\n* `lookupLE`. Raw.\r\n* `lookupGE`. Raw.\r\n\r\n### Construction\r\n* `empty`. Raw.\r\n* `singleton`. Raw.\r\n\r\n#### Insertion\r\n* `insert`. Raw.\r\n* `insertWith`. Raw.\r\n* `insertWithKey`. Delegated, using `insertWith`.\r\n* `insertLookupWithKey`. Raw.\r\n\r\n#### Delete/Update\r\n* `delete`. Raw.\r\n* `adjust`. Raw.\r\n* `adjustWithkey`. Delegated, using `adjust`.\r\n* `update`. Raw.\r\n* `updateWithKey`. Delegated, using `update`.\r\n* `updateLookupWithKey`. Raw.\r\n* `alter`. Delegated, using `member` and either `update` or `insert`.\r\n\r\n### Combine\r\n#### Union\r\n* `union`. Raw.\r\n* `unionWith`. Delegated, using `unionWithKey`.\r\n* `unionWithKey`. Raw.\r\n* `unions`. Delegated, using lots of `union`s.\r\n* `unionsWith`. Delegated, using lots of `unionWith`s.\r\n\r\n#### Difference\r\n* `difference`. Delegated, using `foldrWithKey'` and lots of `delete`s.\r\n* `differenceWith`. Delegated, using `differenceWithKey`.\r\n* `differenceWithKey`. Delegated, using `foldrWithKey'` and lots of `update`s.\r\n\r\n#### Intersection\r\n* `intersection`. Raw. See note on `intersectionWithKey`.\r\n* `intersectionWith`. Delegated, using `intersectionWithKey`.\r\n* `intersectionWithKey`. Raw. Note that it is still slower than stock `Data.IntMap` by up to (though not necessarily) 50%.\r\n\r\n#### Universal combining function\r\n* `mergeWithKey`. _Unimplemented_. Probably never will be implemented, at least in its current form, due to this being very implementation-specific.\r\n\r\n### Traversal\r\n#### Map\r\n* `map`. Raw. Actually, this is sort of delegated to `fmap`, but since the delegation is just `map = fmap` and will probably be inlined, I count this as raw.\r\n* `mapWithKey`. Raw.\r\n* `traverseWithKey`. Raw.\r\n* `mapAccum`. Delegated, using `mapAccumWithKey`.\r\n* `mapAccumWithKey`. Raw.\r\n* `mapAccumRWithKey`. Raw.\r\n* `mapKeys`. Delegated, using `foldrWithKey'` and lots of `insert`s.\r\n* `mapKeysWith`. Delegated, using `foldrWithKey'` and lots of `insertWith`s.\r\n* `mapKeysMonotonic`. Delegated, using `mapKeys`.\r\n\r\n#### Folds\r\n* `foldr`. Raw.\r\n* `foldl`. Raw.\r\n* `foldrWithKey`. Raw.\r\n* `foldlWithKey`. Raw.\r\n* `foldMapWithKey`. Raw.\r\n\r\n#### Strict folds\r\n* `foldr'`. Raw.\r\n* `foldl'`. Raw.\r\n* `foldrWithKey'`. Raw.\r\n* `foldlWithKey'`. Raw.\r\n\r\n### Conversion\r\n* `elems`. Delegated, using `foldr`.\r\n* `keys`. Delegated, using `foldrWithKey`.\r\n* `assocs`. Delegated, using `toAscList`.\r\n* `keysSet`. _Unimplemented_. Note that I'm not sure whether to convert to stock `Data.IntSet` or `Data.WordSet`, which is much more in flux than `Data.WordMap`.\r\n* `fromSet`. _Unimplemented_. Note that I'm not sure whether to convert from stock `Data.IntSet` or `Data.WordSet`, which is much more in flux than `Data.WordMap`.\r\n\r\n#### Lists\r\n* `toList`. Delegated, using `toAscList`.\r\n* `fromList`. Delegated, using lots of `insert`s.\r\n* `fromListWith`. Delegated, using lots of `insert`s.\r\n* `fromListWithKey`. Delegated, using lots of `insert`s.\r\n\r\n#### Ordered lists\r\n* `toAscList`. Delegated, using `foldrWithKey`.\r\n* `toDescList`. Delegated, using `foldlWithKey`.\r\n* `fromAscList`. Delegated, using `fromList`.\r\n* `fromAscListWith`. Delegated, using `fromListWith`.\r\n* `fromAscListWithKey`. Delegated, using `fromListWithKey`.\r\n* `fromDistinctAscList`. Delegated, using `fromList`.\r\n\r\n### Filter\r\n* `filter`. Delegated, using `filterWithKey`.\r\n* `filterWithKey`. Raw.\r\n* `partition`. Delegated, using `partitionWithKey`.\r\n* `partitionWithKey`. Raw.\r\n* `mapMaybe`. Delegated, using `mapMaybeWithKey`.\r\n* `mapMaybeWithKey`. Raw.\r\n* `mapEither`. Delegated, using `mapEitherWithKey`.\r\n* `mapEitherWithKey`. Raw.\r\n* `split`. Delegated, using `splitLookup`.\r\n* `splitLookup`. Raw.\r\n\r\n### Submap\r\n* `isSubmapOf`. _Unimplemented_.\r\n* `isSubmapOfBy`. _Unimplemented_.\r\n* `isProperSubmapOf`. _Unimplemented_\r\n* `isProperSubmapOfBy`. _Unimplemented_.\r\n\r\n### Min/Max\r\n* `findMin`. Raw. Note that this is asymptotically faster than stock `Data.IntMap`.\r\n* `findMax`. Raw. Note that this is asymptotically faster than stock `Data.IntMap`.\r\n* `deleteMin`. Delegated, using `findMin` and `delete`.\r\n* `deleteMax`. Delegated, using `findMin` and `delete`.\r\n* `deleteFindMin`. Delegated, using `findMin` and `delete`.\r\n* `deleteFindMax`. Delegated, using `findMin` and `delete`.\r\n* `updateMin`. Delegated, using `findMin` and `update`.\r\n* `updateMax`. Delegated, using `findMin` and `update`.\r\n* `updateMinWithKey`. Delegated, using `findMin` and `updateWithKey`.\r\n* `updateMaxWithKey`. Delegated, using `findMin` and `updateWithKey`.\r\n* `minView`. Delegated, using `findMin` and `delete`.\r\n* `maxView`. Delegated, using `findMin` and `delete`.\r\n* `minViewWithKey`. Delegated, using `findMin` and `delete`.\r\n* `maxViewWithKey`. Delegated, using `findMin` and `delete`.\r\n\r\n### Debugging\r\nNote that this section shouldn't matter to the average user.\r\n* `showTree`. Raw.\r\n* `showTreeWith`. _Unimplemented_.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}